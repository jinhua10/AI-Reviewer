package top.yumbo.ai.rag.example.llm;

/**
 * æ¨¡æ‹ŸLLMå®¢æˆ·ç«¯
 * ç”¨äºæ¼”ç¤ºå’Œæµ‹è¯•ï¼Œå®é™…ä½¿ç”¨æ—¶åº”æ›¿æ¢ä¸ºçœŸå®çš„LLMå®¢æˆ·ç«¯
 *
 * çœŸå®å®ç°ç¤ºä¾‹ï¼š
 * - OpenAIClient: è°ƒç”¨OpenAI GPT-4 API
 * - ClaudeClient: è°ƒç”¨Anthropic Claude API
 * - LocalLlamaClient: è°ƒç”¨æœ¬åœ°Llamaæ¨¡å‹
 */
public class MockLLMClient implements LLMClient {

    @Override
    public String generate(String prompt) {
        // å®é™…ä½¿ç”¨æ—¶ï¼Œè¿™é‡Œåº”è¯¥è°ƒç”¨çœŸå®çš„LLM API
        // ä¾‹å¦‚ï¼š
        // - OpenAI GPT-4: openai.chat.completions.create(...)
        // - æœ¬åœ°Llama: llama_cpp.generate(...)
        // - Claude: anthropic.messages.create(...)

        return """
            åŸºäºæä¾›çš„æ–‡æ¡£å†…å®¹ï¼Œæˆ‘ä¸ºæ‚¨æ€»ç»“å¦‚ä¸‹ï¼š
            
            [è¿™æ˜¯ä¸€ä¸ªæ¨¡æ‹Ÿå›ç­”ï¼Œå®é™…ä½¿ç”¨æ—¶ä¼šè°ƒç”¨çœŸå®çš„LLM]
            
            1. æ–‡æ¡£ä¸­åŒ…å«äº†è¯¦ç»†çš„æ•°æ®ä¿¡æ¯
            2. æ•°æ®å·²è¢«æˆåŠŸè§£æå¹¶å­˜å‚¨åœ¨çŸ¥è¯†åº“ä¸­
            3. æ‚¨å¯ä»¥é€šè¿‡å…³é”®è¯æœç´¢å¿«é€Ÿæ‰¾åˆ°ç›¸å…³å†…å®¹
            
            ğŸ’¡ æç¤ºï¼šè¯·æ›¿æ¢MockLLMClientä¸ºçœŸå®çš„LLMå®¢æˆ·ç«¯ä»¥è·å¾—å®é™…çš„AIå›ç­”ã€‚
            
            å¯é€‰çš„LLMå®¢æˆ·ç«¯ï¼š
            - OpenAI GPT-4 / GPT-3.5
            - Anthropic Claude
            - æœ¬åœ°Llamaæ¨¡å‹
            - é˜¿é‡Œé€šä¹‰åƒé—®
            - ç™¾åº¦æ–‡å¿ƒä¸€è¨€
            """;
    }
}

