# 知识库问答系统配置文件
# Knowledge QA System Configuration

server:
  port: 8080

spring:
  application:
    name: knowledge-qa-system

# 知识库问答系统配置
knowledge:
  qa:
    # 知识库配置
    knowledge-base:
      # 知识库存储路径（索引、元数据等）
      storage-path: ./data/knowledge-base

      # 文档源路径（支持文件夹或单个文件）
      # 示例：
      #   - ./data/documents           # 文件夹
      #   - E:/文档/知识库             # 中文路径
      #   - ./data/documents/file.xlsx # 单个文件
      source-path: E:/excel

      # 启动时是否重建知识库
      # true: 每次启动时重新构建（适合开发）
      # false: 使用已有知识库（适合生产）
      rebuild-on-startup: false

      # 是否启用缓存
      enable-cache: true

    # 向量检索配置
    vector-search:
      # 是否启用向量检索
      # true: 使用语义向量检索（需要模型文件）
      # false: 使用纯关键词检索
      enabled: true

      # 模型配置
      model:
        # 模型名称（用于日志显示）
        name: paraphrase-multilingual

        # 模型文件路径（相对于 resources）
        # 系统会自动查找以下目录中的模型文件：
        path: /models/paraphrase-multilingual/model.onnx

        # 模型搜索路径（按优先级排序）
        # 系统会按顺序在这些目录中查找模型文件
        search-paths:
          - bge-m3                      # BGE-M3 (推荐, 2024最新)
          - multilingual-e5-large       # Multilingual E5 Large
          - bge-large-zh                # BGE Large ZH (中文)
          - paraphrase-multilingual     # Paraphrase Multilingual
          - text2vec-base-chinese       # Text2Vec (旧版)

        # 模型文件名（按优先级排序）
        file-names:
          - model.onnx                  # 标准模型
          - model_O2.onnx               # 优化模型
          - model_quantized.onnx        # 量化模型
          - model_quint8_avx2.onnx      # AVX2 量化

      # 向量索引存储路径
      index-path: ./data/vector-index

      # 检索相似度阈值 (0.0-1.0)
      # 越高越严格，建议 0.3-0.5
      similarity-threshold: 0.4

      # 检索返回的文档数量
      top-k: 20

    # LLM 配置
    llm:
      # LLM 提供商
      # 可选值:
      #   - mock: 模拟客户端（默认，用于测试）
      #   - openai: OpenAI (GPT-4o, GPT-4, GPT-3.5)
      #   - deepseek: DeepSeek
      provider: mock

      # API Key（从环境变量读取）
      # OpenAI: export OPENAI_API_KEY=sk-your-key
      # 或通用: export AI_API_KEY=your-key
      api-key: ${AI_API_KEY:}

      # API 端点
      # OpenAI 默认: https://api.openai.com/v1/chat/completions
      # DeepSeek: https://api.deepseek.com/v1/chat/completions
      # 自定义端点（如使用代理）: https://your-proxy.com/v1/chat/completions
      api-url: https://api.openai.com/v1/chat/completions

      # 模型名称
      # OpenAI 可选模型:
      #   - gpt-4o (推荐，最新多模态模型，2024)
      #   - gpt-4o-mini (轻量版)
      #   - gpt-4-turbo (GPT-4 Turbo，高性能)
      #   - gpt-4 (GPT-4 标准版)
      #   - gpt-3.5-turbo (经济实惠)
      #   - gpt-5 (未来版本，发布后可用)
      # DeepSeek:
      #   - deepseek-chat
      model: gpt-4o

      # 最大上下文长度（字符数）
      max-context-length: 20000

      # 单文档最大长度（字符数）
      max-doc-length: 5000

    # 文档处理配置
    document:
      # 支持的文件格式
      supported-formats:
        - xlsx
        - xls
        - docx
        - doc
        - pptx
        - ppt
        - pdf
        - txt
        - md
        - html
        - xml

      # 最大文件大小（MB）
      max-file-size-mb: 200

      # 最大内容大小（MB）
      # 超过此大小会强制分块
      max-content-size-mb: 50

      # 自动分块阈值（MB）
      # 内容超过此大小会自动启用分块
      auto-chunk-threshold-mb: 2

      # 文档分块大小（字符数）
      chunk-size: 2000

      # 文档分块重叠（字符数）
      chunk-overlap: 400

    # 图片处理配置
    image-processing:
      # 图片处理策略:
      #   - placeholder: 占位符（默认，零依赖）
      #   - ocr: OCR 文字识别（需要 Tesseract）
      #   - vision-llm: Vision LLM 语义理解（需要 API Key）
      #   - hybrid: 混合模式（OCR + Vision LLM）
      strategy: placeholder

      # 是否启用 OCR
      enable-ocr: false

      # OCR 配置
      ocr:
        # Tesseract 数据路径（从环境变量读取）
        # Linux/Mac: export TESSDATA_PREFIX=/path/to/tessdata
        # Windows: set TESSDATA_PREFIX=C:\path\to\tessdata
        tessdata-path: ${TESSDATA_PREFIX:}

        # 识别语言
        # chi_sim: 简体中文
        # eng: 英文
        # chi_sim+eng: 中英文混合
        language: chi_sim+eng

      # Vision LLM 配置
      vision-llm:
        # 是否启用
        enabled: false

        # API Key（从环境变量读取）
        # export VISION_LLM_API_KEY=sk-your-api-key
        api-key: ${VISION_LLM_API_KEY:}

        # 模型名称
        # - gpt-4-vision-preview (OpenAI)
        # - claude-3-opus (Anthropic)
        # - gemini-pro-vision (Google)
        model: gpt-4-vision-preview

        # API 端点（可选）
        endpoint: ${VISION_LLM_ENDPOINT:}

# 日志配置
logging:
  level:
    root: INFO
    top.yumbo.ai.rag: INFO
    org.springframework: WARN
  pattern:
    console: "%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n"

---
# 开发环境配置
spring:
  config:
    activate:
      on-profile: dev

knowledge:
  qa:
    knowledge-base:
      rebuild-on-startup: true  # 开发时每次重建
    vector-search:
      enabled: true

logging:
  level:
    top.yumbo.ai.rag: DEBUG

---
# 生产环境配置
spring:
  config:
    activate:
      on-profile: prod

knowledge:
  qa:
    knowledge-base:
      rebuild-on-startup: false  # 生产环境使用已有知识库
    vector-search:
      enabled: true

logging:
  level:
    top.yumbo.ai.rag: INFO

