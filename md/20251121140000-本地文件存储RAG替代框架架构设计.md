# 本地文件存储RAG替代框架
## 架构设计文档

**创建时间**: 2025-11-21 14:00:00  
**作者**: GitHub Copilot (高级架构师)  
**版本**: 1.0

---

## 1. 执行摘要

本文档阐述了一个创新框架的架构设计，该框架使用纯本地文件存储方式替代传统的RAG（检索增强生成）系统。该框架消除了对向量数据库和嵌入模型的依赖，同时保持高效的检索能力。

### 1.1 核心目标
- **零外部依赖**: 无需向量数据库、无需嵌入API
- **高性能**: 亚秒级查询响应时间
- **可扩展性**: 本地处理百万级文档
- **隐私优先**: 所有数据保留在本地存储
- **易于集成**: 为现有应用提供简洁的API

---

## 2. 系统架构

### 2.1 高层架构

```
┌─────────────────────────────────────────────────────────────┐
│                     应用层                                    │
│  (REST API / SDK / CLI 接口)                                 │
└───────────────────────┬─────────────────────────────────────┘
                        │
┌───────────────────────▼─────────────────────────────────────┐
│                    核心引擎层                                 │
├──────────────────┬──────────────┬──────────────┬────────────┤
│   查询处理器      │   索引引擎    │   缓存层      │  调度器    │
└──────────┬───────┴───────┬──────┴──────┬───────┴─────┬──────┘
           │               │             │             │
┌──────────▼───────────────▼─────────────▼─────────────▼──────┐
│                    存储层                                     │
├─────────────┬─────────────┬──────────────┬───────────────────┤
│  文件系统    │  索引数据库  │  元数据数据库 │  缓存存储         │
│  (文档)     │  (Lucene)   │  (SQLite)    │  (本地/内存)      │
└─────────────┴─────────────┴──────────────┴───────────────────┘
```

### 2.2 组件分解

#### 2.2.1 存储层
- **文档存储**: 按哈希/分类组织的原始文件
- **索引存储**: 使用Apache Lucene的倒排索引
- **元数据存储**: SQLite数据库用于结构化查询
- **缓存存储**: 热数据缓存 (Caffeine/本地Redis)

#### 2.2.2 核心引擎层
- **解析引擎**: 多格式文档解析
- **索引引擎**: 实时索引构建和更新
- **查询处理器**: 多策略查询执行
- **排序引擎**: BM25、TF-IDF、自定义评分

#### 2.2.3 应用层
- **REST API**: CRUD操作的HTTP端点
- **Java SDK**: 原生集成库
- **CLI工具**: 命令行管理界面
- **管理控制台**: 基于Web的管理界面

---

## 3. 核心模块设计

### 3.1 存储模块 (`storage-core`)

**职责**:
- 文件系统操作（读/写/删除）
- 内容哈希和去重
- 压缩和加密
- 版本管理

**核心类**:
```java
interface StorageEngine {
    String store(Document doc);
    Document retrieve(String id);
    void delete(String id);
    Stream<Document> list(StorageQuery query);
}

interface DocumentHasher {
    String computeHash(byte[] content);
    boolean isDuplicate(String hash);
}

interface VersionManager {
    Version createVersion(String docId);
    List<Version> getHistory(String docId);
    Document rollback(String docId, int version);
}
```

**存储结构**:
```
data/
├── documents/
│   ├── 2025/11/21/
│   │   ├── abc123.txt
│   │   ├── abc123.meta.json
│   │   └── def456.pdf
│   └── ...
├── index/
│   └── lucene-index/
├── metadata/
│   └── metadata.db (SQLite)
└── cache/
    └── hot-cache/
```

### 3.2 索引模块 (`index-core`)

**职责**:
- 使用Lucene进行全文索引
- 增量索引更新
- 索引优化和压缩
- 多字段搜索支持

**核心类**:
```java
interface IndexEngine {
    void indexDocument(Document doc);
    void updateIndex(String docId, Document doc);
    void deleteFromIndex(String docId);
    SearchResult search(Query query);
}

interface QueryParser {
    Query parse(String queryString);
    Query buildBooleanQuery(List<Clause> clauses);
}

interface RankingStrategy {
    List<ScoredDocument> rank(List<Document> candidates, Query query);
}
```

**索引特性**:
- 基于字段的索引（标题、内容、元数据）
- N-gram分词支持模糊匹配
- 短语查询支持
- 分面搜索能力
- 按字段类型自定义分析器

### 3.3 查询模块 (`query-processor`)

**职责**:
- 查询解析和优化
- 多策略检索
- 结果排序和过滤
- 分页和排序

**查询类型**:
1. **精确匹配**: 关键字搜索
2. **模糊搜索**: 容错搜索
3. **短语查询**: 精确短语匹配
4. **布尔查询**: AND/OR/NOT逻辑
5. **范围查询**: 日期/数值范围
6. **通配符查询**: 模式匹配

**查询流水线**:
```
输入查询 → 解析 → 优化 → 执行 → 排序 → 过滤 → 返回
```

### 3.4 解析模块 (`document-parser`)

**支持格式**:
- 文本: `.txt`, `.md`, `.log`
- 文档: `.pdf`, `.docx`, `.xlsx`, `.pptx`
- 代码: `.java`, `.py`, `.js`, `.xml`, `.json`
- 网页: `.html`, `.xml`
- 归档: `.zip`, `.tar.gz`

**核心类**:
```java
interface DocumentParser {
    ParsedDocument parse(File file);
    boolean supports(String mimeType);
}

class ParserRegistry {
    void register(DocumentParser parser);
    DocumentParser getParser(String mimeType);
}
```

### 3.5 缓存模块 (`cache-layer`)

**多级缓存**:
1. **L1缓存**: 内存热点文档 (Caffeine)
2. **L2缓存**: 频繁访问的索引
3. **L3缓存**: 查询结果缓存

**缓存策略**:
- LRU淘汰策略
- 基于时间的过期
- 基于大小的限制
- 常用查询预热

---

## 4. 检索策略

### 4.1 BM25排序

**公式**:
```
score(D,Q) = Σ IDF(qi) · (f(qi,D) · (k1+1)) / (f(qi,D) + k1·(1-b+b·|D|/avgdl))
```

**参数**:
- k1: 词频饱和度 (默认: 1.2)
- b: 长度归一化 (默认: 0.75)

### 4.2 TF-IDF评分

**公式**:
```
TF-IDF(t,d) = TF(t,d) · log(N / DF(t))
```

### 4.3 混合评分

组合多个信号:
```
最终得分 = α·bm25 + β·时效性 + γ·精确匹配 + δ·元数据增强
```

---

## 5. API设计

### 5.1 文档管理API

```java
// 存储文档
POST /api/v1/documents
Body: { "content": "...", "metadata": {...} }
Response: { "id": "doc-123", "status": "indexed" }

// 检索文档
GET /api/v1/documents/{id}
Response: { "id": "doc-123", "content": "...", "metadata": {...} }

// 更新文档
PUT /api/v1/documents/{id}
Body: { "content": "...", "metadata": {...} }

// 删除文档
DELETE /api/v1/documents/{id}
```

### 5.2 搜索API

```java
// 基础搜索
GET /api/v1/search?q=关键字&limit=10&offset=0

// 高级搜索
POST /api/v1/search/advanced
Body: {
    "query": "机器学习",
    "filters": {
        "dateRange": { "start": "2025-01-01", "end": "2025-12-31" },
        "categories": ["技术", "人工智能"]
    },
    "sort": "relevance",
    "limit": 20
}
```

### 5.3 管理API

```java
// 索引统计
GET /api/v1/admin/stats

// 重建索引
POST /api/v1/admin/reindex

// 缓存管理
DELETE /api/v1/admin/cache/clear
```

---

## 6. 性能优化

### 6.1 索引性能
- **批量索引**: 批处理文档
- **并行处理**: 多线程索引
- **增量更新**: 仅索引变更
- **索引分段**: Lucene分段优化

### 6.2 查询性能
- **查询缓存**: 缓存频繁查询
- **过滤器缓存**: 缓存过滤结果
- **文档缓存**: 缓存热点文档
- **提前终止**: 达到K个结果后停止

### 6.3 存储优化
- **压缩**: Gzip/LZ4压缩文档
- **去重**: 基于内容的哈希
- **分层存储**: 热/温/冷数据分离
- **清理任务**: 删除孤立文件

---

## 7. 可扩展性考虑

### 7.1 垂直扩展
- 优化JVM堆大小
- 使用内存映射文件
- 增加磁盘I/O并行度

### 7.2 水平扩展
- 按文档ID范围分片
- 复制以提高读取可扩展性
- 分布式查询协调

### 7.3 容量规划

| 文档数量 | 索引大小 | 内存 | 磁盘空间 |
|---------|---------|------|---------|
| 10万    | ~500MB  | 2GB  | 10GB    |
| 100万   | ~5GB    | 8GB  | 100GB   |
| 1000万  | ~50GB   | 32GB | 1TB     |

---

## 8. 安全与隐私

### 8.1 数据保护
- **静态加密**: AES-256加密文档
- **访问控制**: 基于角色的权限
- **审计日志**: 跟踪所有操作

### 8.2 隐私特性
- **本地处理**: 数据不离开本机
- **PII脱敏**: 自动敏感数据掩码
- **安全删除**: 加密粉碎

---

## 9. 技术栈

### 9.1 核心依赖

| 组件 | 技术 | 版本 |
|-----|------|-----|
| 搜索引擎 | Apache Lucene | 9.x |
| 元数据数据库 | SQLite JDBC | 3.44+ |
| 文档解析器 | Apache Tika | 2.9+ |
| 缓存 | Caffeine | 3.1+ |
| HTTP服务器 | Netty | 4.1+ |
| JSON处理 | Jackson | 2.15+ |
| 日志 | SLF4J + Logback | 2.0+ |

### 9.2 构建与打包
- **构建工具**: Maven 3.9+
- **Java版本**: Java 17+
- **打包**: 带依赖的可执行JAR

---

## 10. 项目结构

```
local-file-rag/
├── pom.xml
├── README.md
├── docs/
├── local-file-rag-api/               # API模块
│   └── src/main/java/com/framework/api/
├── local-file-rag-core/              # 核心模块
│   └── src/main/java/com/framework/core/
│       ├── storage/                  # 存储子模块
│       ├── index/                    # 索引子模块
│       ├── query/                    # 查询子模块
│       └── cache/                    # 缓存子模块
├── local-file-rag-parser/            # 解析器模块
│   └── src/main/java/com/framework/parser/
├── local-file-rag-server/            # 服务器模块
│   └── src/main/java/com/framework/server/
└── local-file-rag-cli/               # CLI模块
    └── src/main/java/com/framework/cli/
```

---

## 11. 实施路线图

### 第一阶段: 基础建设 (第1-2周)
- [ ] 搭建项目结构
- [ ] 实现存储层
- [ ] 基础文件I/O操作
- [ ] 文档哈希

### 第二阶段: 索引功能 (第3-4周)
- [ ] 集成Apache Lucene
- [ ] 实现索引引擎
- [ ] 构建解析器框架
- [ ] 添加常见格式解析器

### 第三阶段: 查询处理 (第5-6周)
- [ ] 查询解析器实现
- [ ] 排序算法 (BM25, TF-IDF)
- [ ] 结果过滤和排序
- [ ] 分页支持

### 第四阶段: API层 (第7-8周)
- [ ] REST API实现
- [ ] Java SDK开发
- [ ] API文档
- [ ] 客户端示例

### 第五阶段: 优化 (第9-10周)
- [ ] 缓存层集成
- [ ] 性能调优
- [ ] 批处理
- [ ] 负载测试

### 第六阶段: 高级特性 (第11-12周)
- [ ] 加密支持
- [ ] 管理控制台
- [ ] 监控与指标
- [ ] 文档与示例

---

## 12. 与传统RAG的对比

| 方面 | 传统RAG | 本框架 |
|-----|--------|-------|
| **存储** | 向量数据库 | 本地文件系统 |
| **检索** | 嵌入相似度 | BM25/TF-IDF |
| **依赖** | OpenAI API、Pinecone等 | 自包含 |
| **延迟** | 网络+计算 | 仅本地I/O |
| **成本** | API调用+数据库托管 | 仅硬件 |
| **隐私** | 数据发送到云端 | 完全本地 |
| **准确性** | 语义搜索 | 关键字+排序 |
| **设置** | 复杂 | 简单 |

---

## 13. 使用场景

### 13.1 理想场景
- **企业文档管理**: 内部知识库
- **代码搜索**: 源代码仓库
- **法律/合规**: 文档审计跟踪
- **研究**: 学术论文集合
- **个人知识**: 笔记系统

### 13.2 不推荐场景
- 语义搜索需求
- 多语言语义理解
- 需要推理的问答系统
- 实时协作编辑

---

## 14. 未来增强

### 14.1 高级特性
- **机器学习集成**: 本地ML模型用于排序
- **基于图的搜索**: 文档关系映射
- **版本控制系统**: 类Git的文档版本控制
- **插件架构**: 自定义解析器/索引器插件

### 14.2 社区特性
- **预构建解析器**: 社区解析器市场
- **索引模板**: 领域特定的索引配置
- **仪表板**: 可视化分析和洞察

---

## 15. 结论

本框架为需要本地处理或偏好本地处理的场景提供了一个强大的、保护隐私的传统RAG系统替代方案。通过利用Apache Lucene等成熟技术并专注于基于关键字的检索，它提供了可预测的性能和完整的数据主权。

模块化架构允许轻松定制和扩展，使其适用于广泛的文档管理和搜索应用。

---

## 附录A: 配置示例

```yaml
framework:
  storage:
    basePath: "./data"
    compression: true
    encryption:
      enabled: false
      algorithm: "AES-256"
  
  index:
    analyzer: "standard"
    mergePolicy: "tiered"
    commitInterval: 30s
    maxBufferedDocs: 1000
  
  cache:
    documentCache:
      size: 1000
      ttl: 3600s
    queryCache:
      size: 10000
      ttl: 300s
  
  server:
    port: 8080
    threads: 100
    requestTimeout: 30s
```

## 附录B: 示例代码

```java
// 初始化框架
LocalFileRAG framework = LocalFileRAG.builder()
    .storagePath("./data")
    .enableCache(true)
    .build();

// 索引文档
Document doc = Document.builder()
    .content("这是一个示例文档")
    .metadata(Map.of("author", "张三"))
    .build();
String docId = framework.index(doc);

// 搜索文档
SearchResult result = framework.search(
    Query.of("示例文档")
        .withLimit(10)
        .withFilter("author", "张三")
);

// 获取最佳结果
List<Document> docs = result.getDocuments();
```

---

## 附录C: 详细模块说明

### C.1 存储模块详细设计

**文档存储策略**:
```java
public class DocumentStorageStrategy {
    // 按日期分区存储
    private String getStoragePath(Document doc) {
        LocalDate date = doc.getCreatedDate();
        return String.format("documents/%d/%02d/%02d/", 
            date.getYear(), date.getMonthValue(), date.getDayOfMonth());
    }
    
    // 内容哈希计算
    private String computeContentHash(byte[] content) {
        MessageDigest digest = MessageDigest.getInstance("SHA-256");
        byte[] hash = digest.digest(content);
        return Base64.getEncoder().encodeToString(hash);
    }
    
    // 去重检查
    public boolean isDuplicate(String hash) {
        return hashIndex.containsKey(hash);
    }
}
```

**元数据管理**:
```sql
-- 文档元数据表
CREATE TABLE documents (
    id TEXT PRIMARY KEY,
    hash TEXT NOT NULL,
    file_path TEXT NOT NULL,
    file_size INTEGER,
    mime_type TEXT,
    created_at TIMESTAMP,
    updated_at TIMESTAMP,
    metadata JSON
);

-- 哈希索引表
CREATE TABLE hash_index (
    hash TEXT PRIMARY KEY,
    document_id TEXT,
    FOREIGN KEY (document_id) REFERENCES documents(id)
);

-- 全文搜索虚拟表
CREATE VIRTUAL TABLE documents_fts USING fts5(
    content, 
    title, 
    author,
    content=documents
);
```

### C.2 索引模块详细设计

**Lucene索引配置**:
```java
public class IndexConfiguration {
    public IndexWriterConfig createWriterConfig() {
        Analyzer analyzer = new StandardAnalyzer();
        IndexWriterConfig config = new IndexWriterConfig(analyzer);
        
        // 合并策略
        TieredMergePolicy mergePolicy = new TieredMergePolicy();
        mergePolicy.setMaxMergedSegmentMB(512);
        config.setMergePolicy(mergePolicy);
        
        // RAM缓冲
        config.setRAMBufferSizeMB(256);
        
        // 提交策略
        config.setCommitOnClose(true);
        
        return config;
    }
    
    // 自定义中文分析器
    public Analyzer createChineseAnalyzer() {
        return new Analyzer() {
            @Override
            protected TokenStreamComponents createComponents(String fieldName) {
                Tokenizer tokenizer = new StandardTokenizer();
                TokenStream filter = new LowerCaseFilter(tokenizer);
                filter = new StopFilter(filter, ChineseStopWords.get());
                return new TokenStreamComponents(tokenizer, filter);
            }
        };
    }
}
```

**索引字段定义**:
```java
public class DocumentIndexer {
    public void indexDocument(IndexWriter writer, Document doc) throws IOException {
        org.apache.lucene.document.Document luceneDoc = 
            new org.apache.lucene.document.Document();
        
        // 存储字段
        luceneDoc.add(new StringField("id", doc.getId(), Field.Store.YES));
        luceneDoc.add(new StoredField("title", doc.getTitle()));
        
        // 索引字段
        luceneDoc.add(new TextField("content", doc.getContent(), Field.Store.NO));
        luceneDoc.add(new TextField("title", doc.getTitle(), Field.Store.YES));
        
        // 排序字段
        luceneDoc.add(new NumericDocValuesField("created_at", 
            doc.getCreatedAt().toEpochMilli()));
        
        // 过滤字段
        luceneDoc.add(new StringField("category", doc.getCategory(), Field.Store.YES));
        
        writer.addDocument(luceneDoc);
    }
}
```

### C.3 查询模块详细设计

**查询构建器**:
```java
public class QueryBuilder {
    private final QueryParser parser;
    
    // 构建布尔查询
    public Query buildBooleanQuery(String text, Map<String, String> filters) {
        BooleanQuery.Builder builder = new BooleanQuery.Builder();
        
        // 主查询
        Query mainQuery = parser.parse(text);
        builder.add(mainQuery, BooleanClause.Occur.MUST);
        
        // 过滤条件
        filters.forEach((field, value) -> {
            Query filter = new TermQuery(new Term(field, value));
            builder.add(filter, BooleanClause.Occur.FILTER);
        });
        
        return builder.build();
    }
    
    // 构建模糊查询
    public Query buildFuzzyQuery(String field, String text, int maxEdits) {
        return new FuzzyQuery(new Term(field, text), maxEdits);
    }
    
    // 构建范围查询
    public Query buildRangeQuery(String field, long start, long end) {
        return LongPoint.newRangeQuery(field, start, end);
    }
    
    // 构建短语查询
    public Query buildPhraseQuery(String field, String phrase, int slop) {
        PhraseQuery.Builder builder = new PhraseQuery.Builder();
        builder.setSlop(slop);
        
        String[] terms = phrase.split("\\s+");
        for (String term : terms) {
            builder.add(new Term(field, term));
        }
        
        return builder.build();
    }
}
```

**高级排序**:
```java
public class AdvancedRanking {
    // 混合评分
    public float computeHybridScore(Document doc, Query query, float luceneScore) {
        float bm25Score = luceneScore;
        float recencyScore = computeRecencyScore(doc);
        float exactMatchScore = computeExactMatchScore(doc, query);
        float metadataBoost = computeMetadataBoost(doc);
        
        return 0.5f * bm25Score + 
               0.2f * recencyScore + 
               0.2f * exactMatchScore + 
               0.1f * metadataBoost;
    }
    
    // 时效性评分
    private float computeRecencyScore(Document doc) {
        long ageInDays = ChronoUnit.DAYS.between(
            doc.getCreatedAt(), Instant.now());
        return 1.0f / (1.0f + (float)Math.log(1 + ageInDays));
    }
    
    // 精确匹配评分
    private float computeExactMatchScore(Document doc, Query query) {
        String queryText = extractQueryText(query);
        String content = doc.getContent().toLowerCase();
        return content.contains(queryText.toLowerCase()) ? 1.0f : 0.0f;
    }
    
    // 元数据增强
    private float computeMetadataBoost(Document doc) {
        float boost = 1.0f;
        if (doc.getMetadata().containsKey("important")) {
            boost *= 1.5f;
        }
        if (doc.getMetadata().containsKey("verified")) {
            boost *= 1.2f;
        }
        return boost;
    }
}
```

### C.4 缓存模块详细设计

**多级缓存实现**:
```java
public class MultiLevelCache {
    private final Cache<String, Document> l1Cache;  // 内存缓存
    private final Cache<String, byte[]> l2Cache;    // 压缩缓存
    private final Cache<String, SearchResult> queryCache;  // 查询缓存
    
    public MultiLevelCache() {
        // L1: 热点文档缓存
        this.l1Cache = Caffeine.newBuilder()
            .maximumSize(1000)
            .expireAfterAccess(Duration.ofMinutes(30))
            .recordStats()
            .build();
        
        // L2: 压缩文档缓存
        this.l2Cache = Caffeine.newBuilder()
            .maximumSize(10000)
            .expireAfterWrite(Duration.ofHours(2))
            .build();
        
        // 查询结果缓存
        this.queryCache = Caffeine.newBuilder()
            .maximumSize(5000)
            .expireAfterWrite(Duration.ofMinutes(10))
            .build();
    }
    
    public Document getDocument(String id) {
        // 先查L1
        Document doc = l1Cache.getIfPresent(id);
        if (doc != null) return doc;
        
        // 再查L2
        byte[] compressed = l2Cache.getIfPresent(id);
        if (compressed != null) {
            doc = decompress(compressed);
            l1Cache.put(id, doc);
            return doc;
        }
        
        // 从存储加载
        doc = loadFromStorage(id);
        if (doc != null) {
            l1Cache.put(id, doc);
            l2Cache.put(id, compress(doc));
        }
        
        return doc;
    }
    
    public SearchResult search(String queryKey, Supplier<SearchResult> loader) {
        return queryCache.get(queryKey, key -> loader.get());
    }
}
```

### C.5 监控与指标

**性能指标收集**:
```java
public class PerformanceMetrics {
    private final MetricRegistry registry = new MetricRegistry();
    
    // 索引指标
    private final Counter documentsIndexed = registry.counter("index.documents.total");
    private final Timer indexingTime = registry.timer("index.time");
    private final Histogram documentSize = registry.histogram("index.document.size");
    
    // 查询指标
    private final Counter queriesExecuted = registry.counter("query.total");
    private final Timer queryTime = registry.timer("query.time");
    private final Histogram resultCount = registry.histogram("query.result.count");
    
    // 缓存指标
    private final Gauge<Double> cacheHitRate = registry.gauge("cache.hit.rate", 
        () -> () -> calculateCacheHitRate());
    
    // 存储指标
    private final Gauge<Long> totalStorageSize = registry.gauge("storage.size.bytes",
        () -> () -> calculateTotalStorageSize());
    
    public void recordIndexing(long durationMs, long docSize) {
        documentsIndexed.inc();
        indexingTime.update(durationMs, TimeUnit.MILLISECONDS);
        documentSize.update(docSize);
    }
    
    public void recordQuery(long durationMs, int resultCount) {
        queriesExecuted.inc();
        queryTime.update(durationMs, TimeUnit.MILLISECONDS);
        this.resultCount.update(resultCount);
    }
}
```

**健康检查**:
```java
public class HealthCheck {
    public HealthStatus checkHealth() {
        HealthStatus status = new HealthStatus();
        
        // 检查存储
        status.add("storage", checkStorage());
        
        // 检查索引
        status.add("index", checkIndex());
        
        // 检查缓存
        status.add("cache", checkCache());
        
        // 检查数据库
        status.add("database", checkDatabase());
        
        return status;
    }
    
    private ComponentHealth checkStorage() {
        try {
            Path storagePath = Paths.get(config.getStoragePath());
            long freeSpace = Files.getFileStore(storagePath).getUsableSpace();
            
            if (freeSpace < 1024 * 1024 * 1024) { // < 1GB
                return ComponentHealth.unhealthy("Low disk space: " + freeSpace);
            }
            
            return ComponentHealth.healthy();
        } catch (Exception e) {
            return ComponentHealth.unhealthy("Storage check failed: " + e.getMessage());
        }
    }
    
    private ComponentHealth checkIndex() {
        try {
            IndexReader reader = indexEngine.getReader();
            int numDocs = reader.numDocs();
            return ComponentHealth.healthy("Indexed documents: " + numDocs);
        } catch (Exception e) {
            return ComponentHealth.unhealthy("Index check failed: " + e.getMessage());
        }
    }
}
```

---

## 附录D: 部署指南

### D.1 单机部署

**系统要求**:
```
- CPU: 4核心+
- 内存: 8GB+
- 磁盘: 100GB+ SSD推荐
- Java: 17+
- 操作系统: Linux/Windows/macOS
```

**部署步骤**:
```bash
# 1. 下载发行版
wget https://github.com/yourorg/local-file-rag/releases/download/v1.0/local-file-rag-1.0.tar.gz
tar -xzf local-file-rag-1.0.tar.gz
cd local-file-rag-1.0

# 2. 配置
cp config/application.yml.example config/application.yml
vim config/application.yml

# 3. 启动
./bin/start.sh

# 4. 验证
curl http://localhost:8080/api/v1/health
```

### D.2 Docker部署

**Dockerfile**:
```dockerfile
FROM eclipse-temurin:17-jre-alpine

WORKDIR /app

COPY target/local-file-rag-server.jar app.jar
COPY config/application.yml config/

EXPOSE 8080

VOLUME ["/app/data"]

ENTRYPOINT ["java", "-jar", "app.jar"]
```

**Docker Compose**:
```yaml
version: '3.8'

services:
  local-file-rag:
    image: local-file-rag:1.0
    ports:
      - "8080:8080"
    volumes:
      - ./data:/app/data
      - ./config:/app/config
    environment:
      - JAVA_OPTS=-Xmx4g -Xms2g
    restart: unless-stopped
```

### D.3 性能调优

**JVM参数**:
```bash
java -Xmx8g -Xms4g \
     -XX:+UseG1GC \
     -XX:MaxGCPauseMillis=200 \
     -XX:+UseStringDeduplication \
     -XX:+ParallelRefProcEnabled \
     -jar local-file-rag-server.jar
```

**Lucene优化**:
```yaml
index:
  ramBufferSizeMB: 512
  maxBufferedDocs: 10000
  useCompoundFile: false
  mergeScheduler:
    maxThreadCount: 4
    maxMergeCount: 6
```

---

## 附录E: 故障排查

### E.1 常见问题

**问题1: 索引性能慢**
```
症状: 文档索引速度低于预期
原因: RAM缓冲区太小，频繁提交
解决: 增加ramBufferSizeMB到256-512MB
```

**问题2: 查询延迟高**
```
症状: 查询响应时间超过1秒
原因: 缓存未命中，索引未优化
解决: 
  1. 启用查询缓存
  2. 定期优化索引（forcemerge）
  3. 增加文档缓存大小
```

**问题3: 内存溢出**
```
症状: OutOfMemoryError
原因: 堆内存不足，缓存过大
解决:
  1. 增加JVM堆内存
  2. 减少缓存大小
  3. 启用对象池
```

### E.2 日志配置

```xml
<!-- logback.xml -->
<configuration>
    <appender name="FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>logs/application.log</file>
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <fileNamePattern>logs/application-%d{yyyy-MM-dd}.log</fileNamePattern>
            <maxHistory>30</maxHistory>
        </rollingPolicy>
        <encoder>
            <pattern>%d{HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n</pattern>
        </encoder>
    </appender>
    
    <logger name="com.framework" level="INFO"/>
    <logger name="org.apache.lucene" level="WARN"/>
    
    <root level="INFO">
        <appender-ref ref="FILE"/>
    </root>
</configuration>
```

---

**文档结束**

本架构设计为构建高性能、隐私保护的本地文件存储检索系统提供了完整的技术方案。通过合理的模块划分、成熟的技术选型和详细的实施计划，该框架能够有效替代传统RAG系统在特定场景下的应用。

